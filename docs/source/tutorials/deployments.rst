.. File: docs/source/tutorials/deployment.rst

Deployment Guide
================

This comprehensive guide covers deploying Python Mastery Hub in production environments, 
from simple single-server setups to large-scale, high-availability deployments across 
multiple cloud providers.

.. note::
   **Prerequisites**: Complete :doc:`getting_started`, :doc:`basic_usage`, and 
   :doc:`advanced_features` tutorials. Basic knowledge of Docker, databases, and 
   web servers is recommended.

What You'll Learn
-----------------

This deployment guide covers:

- ğŸš€ **Deployment Options**: Single server, containerized, and cloud deployments
- ğŸ³ **Docker Deployment**: Containerized deployment with Docker Compose
- â˜ï¸ **Cloud Platforms**: AWS, Google Cloud, Azure, and DigitalOcean
- âš–ï¸ **Load Balancing**: High-availability and scalable architectures
- ğŸ”’ **Security**: SSL/TLS, firewalls, and security best practices
- ğŸ“Š **Monitoring**: Logging, metrics, and alerting setup
- ğŸ’¾ **Backup & Recovery**: Data protection and disaster recovery
- ğŸ”§ **Maintenance**: Updates, scaling, and troubleshooting

Deployment Architecture Overview
-------------------------------

Production Deployment Components
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

A production Python Mastery Hub deployment typically includes:

.. code-block:: text

   Production Architecture:
   
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚   Load Balancer â”‚â”€â”€â”€â”€â”‚   Web Servers    â”‚â”€â”€â”€â”€â”‚    Database     â”‚
   â”‚   (Nginx/HAProxyâ”‚    â”‚   (PMH App)      â”‚    â”‚  (PostgreSQL)   â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                       â”‚                       â”‚
            â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
            â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚  Cache Layer     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
                           â”‚   (Redis)        â”‚
                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           â”‚  File Storage    â”‚
                           â”‚ (S3/MinIO/Local) â”‚
                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

**Core Components:**

1. **Load Balancer**: Routes traffic and provides SSL termination
2. **Web Servers**: Multiple application instances for scalability
3. **Database**: PostgreSQL for persistent data storage
4. **Cache Layer**: Redis for session storage and caching
5. **File Storage**: Object storage for user uploads and media
6. **Monitoring**: Prometheus, Grafana, and log aggregation

**Deployment Tiers:**

- **Development**: Single container for testing
- **Staging**: Multi-container setup mirroring production
- **Production**: High-availability, scalable infrastructure

Simple Single-Server Deployment
-------------------------------

For small to medium deployments, a single server can handle significant load.

Server Requirements
~~~~~~~~~~~~~~~~~~

**Minimum Requirements:**
- **CPU**: 2 cores
- **RAM**: 4GB
- **Storage**: 20GB SSD
- **OS**: Ubuntu 20.04+ or CentOS 8+
- **Network**: 1Gbps connection

**Recommended (Medium Load):**
- **CPU**: 4 cores
- **RAM**: 8GB
- **Storage**: 50GB SSD
- **OS**: Ubuntu 22.04 LTS

**High Performance:**
- **CPU**: 8+ cores
- **RAM**: 16GB+
- **Storage**: 100GB+ NVMe SSD
- **OS**: Ubuntu 22.04 LTS

Server Setup
~~~~~~~~~~~

**1. System Preparation:**

.. code-block:: bash

   # Update system
   sudo apt update && sudo apt upgrade -y
   
   # Install essential packages
   sudo apt install -y curl wget git nginx postgresql postgresql-contrib \
                       redis-server python3 python3-pip python3-venv \
                       software-properties-common apt-transport-https \
                       ca-certificates gnupg lsb-release ufw fail2ban
   
   # Create application user
   sudo useradd -m -s /bin/bash pmhuser
   sudo usermod -aG sudo pmhuser

**2. Python Mastery Hub Installation:**

.. code-block:: bash

   # Switch to application user
   sudo su - pmhuser
   
   # Create application directory
   mkdir -p /home/pmhuser/pmh
   cd /home/pmhuser/pmh
   
   # Create virtual environment
   python3 -m venv pmh-env
   source pmh-env/bin/activate
   
   # Install Python Mastery Hub
   pip install python-mastery-hub[production]
   
   # Generate configuration
   pmh config generate --env production --output production-config.yaml

**3. Database Setup:**

.. code-block:: bash

   # Switch to postgres user
   sudo su - postgres
   
   # Create database and user
   psql << EOF
   CREATE DATABASE pmh_production;
   CREATE USER pmhuser WITH ENCRYPTED PASSWORD 'secure_password_here';
   GRANT ALL PRIVILEGES ON DATABASE pmh_production TO pmhuser;
   ALTER USER pmhuser CREATEDB;  -- For running migrations
   \q
   EOF
   
   # Exit postgres user
   exit
   
   # Configure database connection
   sudo su - pmhuser
   cd /home/pmhuser/pmh
   source pmh-env/bin/activate
   
   # Update database URL in configuration
   pmh config set database.url "postgresql://pmhuser:secure_password_here@localhost/pmh_production"
   
   # Initialize database
   pmh db init

**4. Redis Configuration:**

.. code-block:: bash

   # Configure Redis
   sudo nano /etc/redis/redis.conf
   
   # Update these settings:
   # bind 127.0.0.1
   # requirepass your_redis_password
   # maxmemory 1gb
   # maxmemory-policy allkeys-lru
   
   # Restart Redis
   sudo systemctl restart redis-server
   sudo systemctl enable redis-server

**5. Nginx Configuration:**

.. code-block:: nginx

   # /etc/nginx/sites-available/pmh
   server {
       listen 80;
       server_name your-domain.com www.your-domain.com;
       
       # Redirect HTTP to HTTPS
       return 301 https://$server_name$request_uri;
   }
   
   server {
       listen 443 ssl http2;
       server_name your-domain.com www.your-domain.com;
       
       # SSL Configuration (Let's Encrypt)
       ssl_certificate /etc/letsencrypt/live/your-domain.com/fullchain.pem;
       ssl_certificate_key /etc/letsencrypt/live/your-domain.com/privkey.pem;
       ssl_session_timeout 1d;
       ssl_session_cache shared:MozTLS:10m;
       ssl_session_tickets off;
       ssl_protocols TLSv1.2 TLSv1.3;
       ssl_ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256;
       ssl_prefer_server_ciphers off;
       
       # Security headers
       add_header Strict-Transport-Security "max-age=63072000" always;
       add_header X-Frame-Options DENY always;
       add_header X-Content-Type-Options nosniff always;
       add_header X-XSS-Protection "1; mode=block" always;
       
       # File upload limit
       client_max_body_size 100M;
       
       # Static files
       location /static/ {
           alias /home/pmhuser/pmh/static/;
           expires 1y;
           add_header Cache-Control "public, immutable";
       }
       
       # Media files
       location /media/ {
           alias /home/pmhuser/pmh/media/;
           expires 1y;
           add_header Cache-Control "public";
       }
       
       # Main application
       location / {
           proxy_pass http://127.0.0.1:8000;
           proxy_set_header Host $host;
           proxy_set_header X-Real-IP $remote_addr;
           proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
           proxy_set_header X-Forwarded-Proto $scheme;
           proxy_redirect off;
           
           # Timeouts
           proxy_connect_timeout 60s;
           proxy_send_timeout 60s;
           proxy_read_timeout 60s;
       }
       
       # WebSocket support
       location /ws/ {
           proxy_pass http://127.0.0.1:8000;
           proxy_http_version 1.1;
           proxy_set_header Upgrade $http_upgrade;
           proxy_set_header Connection "upgrade";
           proxy_set_header Host $host;
           proxy_set_header X-Real-IP $remote_addr;
           proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
           proxy_set_header X-Forwarded-Proto $scheme;
       }
   }

**6. SSL Certificate (Let's Encrypt):**

.. code-block:: bash

   # Install Certbot
   sudo apt install certbot python3-certbot-nginx
   
   # Obtain SSL certificate
   sudo certbot --nginx -d your-domain.com -d www.your-domain.com
   
   # Enable automatic renewal
   sudo crontab -e
   # Add this line:
   # 0 12 * * * /usr/bin/certbot renew --quiet

**7. Systemd Service:**

.. code-block:: ini

   # /etc/systemd/system/pmh.service
   [Unit]
   Description=Python Mastery Hub
   After=network.target postgresql.service redis.service
   Requires=postgresql.service redis.service
   
   [Service]
   Type=notify
   User=pmhuser
   Group=pmhuser
   WorkingDirectory=/home/pmhuser/pmh
   Environment=PATH=/home/pmhuser/pmh/pmh-env/bin
   Environment=PMH_CONFIG_FILE=/home/pmhuser/pmh/production-config.yaml
   ExecStart=/home/pmhuser/pmh/pmh-env/bin/pmh web start --host 127.0.0.1 --port 8000 --workers 4
   ExecReload=/bin/kill -s HUP $MAINPID
   Restart=always
   RestartSec=10
   
   [Install]
   WantedBy=multi-user.target

**8. Start Services:**

.. code-block:: bash

   # Enable Nginx site
   sudo ln -s /etc/nginx/sites-available/pmh /etc/nginx/sites-enabled/
   sudo nginx -t
   sudo systemctl restart nginx
   sudo systemctl enable nginx
   
   # Start PMH service
   sudo systemctl daemon-reload
   sudo systemctl start pmh
   sudo systemctl enable pmh
   
   # Check service status
   sudo systemctl status pmh

Docker Deployment
-----------------

Container-based deployment provides consistency and easier management.

Docker Compose Setup
~~~~~~~~~~~~~~~~~~~

**1. Directory Structure:**

.. code-block:: text

   pmh-docker/
   â”œâ”€â”€ docker-compose.yml
   â”œâ”€â”€ docker-compose.override.yml
   â”œâ”€â”€ .env
   â”œâ”€â”€ nginx/
   â”‚   â”œâ”€â”€ nginx.conf
   â”‚   â””â”€â”€ ssl/
   â”œâ”€â”€ postgres/
   â”‚   â””â”€â”€ init/
   â””â”€â”€ data/
       â”œâ”€â”€ postgres/
       â”œâ”€â”€ redis/
       â””â”€â”€ uploads/

**2. Environment Configuration:**

.. code-block:: bash

   # .env file
   COMPOSE_PROJECT_NAME=pmh
   
   # Database
   POSTGRES_DB=pmh_production
   POSTGRES_USER=pmhuser
   POSTGRES_PASSWORD=secure_db_password
   POSTGRES_PORT=5432
   
   # Redis
   REDIS_PASSWORD=secure_redis_password
   REDIS_PORT=6379
   
   # Application
   PMH_SECRET_KEY=your_secret_key_here
   PMH_ENVIRONMENT=production
   PMH_DEBUG=false
   PMH_HOST=0.0.0.0
   PMH_PORT=8000
   PMH_WORKERS=4
   
   # SSL
   SSL_CERT_PATH=./nginx/ssl/fullchain.pem
   SSL_KEY_PATH=./nginx/ssl/privkey.pem
   
   # Domain
   DOMAIN_NAME=your-domain.com

**3. Docker Compose Configuration:**

.. code-block:: yaml

   # docker-compose.yml
   version: '3.8'
   
   services:
     nginx:
       image: nginx:alpine
       container_name: pmh-nginx
       ports:
         - "80:80"
         - "443:443"
       volumes:
         - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
         - ./nginx/ssl:/etc/nginx/ssl:ro
         - static_volume:/app/static:ro
         - media_volume:/app/media:ro
       depends_on:
         - web
       restart: unless-stopped
       networks:
         - pmh-network
   
     web:
       image: pythonmasteryhub/pmh:latest
       container_name: pmh-web
       environment:
         - PMH_DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:${POSTGRES_PORT}/${POSTGRES_DB}
         - PMH_REDIS_URL=redis://redis:${REDIS_PORT}/0
         - PMH_SECRET_KEY=${PMH_SECRET_KEY}
         - PMH_ENVIRONMENT=${PMH_ENVIRONMENT}
         - PMH_DEBUG=${PMH_DEBUG}
       volumes:
         - static_volume:/app/static
         - media_volume:/app/media
         - ./data/uploads:/app/uploads
       depends_on:
         - postgres
         - redis
       restart: unless-stopped
       networks:
         - pmh-network
       healthcheck:
         test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
         interval: 30s
         timeout: 10s
         retries: 3
   
     postgres:
       image: postgres:15-alpine
       container_name: pmh-postgres
       environment:
         - POSTGRES_DB=${POSTGRES_DB}
         - POSTGRES_USER=${POSTGRES_USER}
         - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
       volumes:
         - postgres_data:/var/lib/postgresql/data
         - ./postgres/init:/docker-entrypoint-initdb.d:ro
       restart: unless-stopped
       networks:
         - pmh-network
       healthcheck:
         test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
         interval: 10s
         timeout: 5s
         retries: 5
   
     redis:
       image: redis:7-alpine
       container_name: pmh-redis
       command: redis-server --requirepass ${REDIS_PASSWORD} --maxmemory 1gb --maxmemory-policy allkeys-lru
       volumes:
         - redis_data:/data
       restart: unless-stopped
       networks:
         - pmh-network
       healthcheck:
         test: ["CMD", "redis-cli", "ping"]
         interval: 10s
         timeout: 5s
         retries: 3
   
     # Background task processor
     worker:
       image: pythonmasteryhub/pmh:latest
       container_name: pmh-worker
       command: pmh worker start
       environment:
         - PMH_DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:${POSTGRES_PORT}/${POSTGRES_DB}
         - PMH_REDIS_URL=redis://redis:${REDIS_PORT}/0
         - PMH_SECRET_KEY=${PMH_SECRET_KEY}
         - PMH_ENVIRONMENT=${PMH_ENVIRONMENT}
       depends_on:
         - postgres
         - redis
       restart: unless-stopped
       networks:
         - pmh-network
   
   volumes:
     postgres_data:
     redis_data:
     static_volume:
     media_volume:
   
   networks:
     pmh-network:
       driver: bridge

**4. Production Override:**

.. code-block:: yaml

   # docker-compose.override.yml (for production)
   version: '3.8'
   
   services:
     web:
       deploy:
         replicas: 3
         resources:
           limits:
             memory: 1G
             cpus: '0.5'
           reservations:
             memory: 512M
             cpus: '0.25'
   
     postgres:
       deploy:
         resources:
           limits:
             memory: 2G
             cpus: '1.0'
           reservations:
             memory: 1G
             cpus: '0.5'
   
     redis:
       deploy:
         resources:
           limits:
             memory: 512M
             cpus: '0.25'

**5. Nginx Configuration for Docker:**

.. code-block:: nginx

   # nginx/nginx.conf
   events {
       worker_connections 1024;
   }
   
   http {
       upstream pmh_backend {
           server web:8000;
       }
       
       server {
           listen 80;
           server_name _;
           return 301 https://$host$request_uri;
       }
       
       server {
           listen 443 ssl http2;
           server_name _;
           
           ssl_certificate /etc/nginx/ssl/fullchain.pem;
           ssl_certificate_key /etc/nginx/ssl/privkey.pem;
           
           location /static/ {
               alias /app/static/;
               expires 1y;
           }
           
           location /media/ {
               alias /app/media/;
               expires 1y;
           }
           
           location / {
               proxy_pass http://pmh_backend;
               proxy_set_header Host $host;
               proxy_set_header X-Real-IP $remote_addr;
               proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
               proxy_set_header X-Forwarded-Proto $scheme;
           }
       }
   }

**6. Deployment Commands:**

.. code-block:: bash

   # Start services
   docker-compose up -d
   
   # View logs
   docker-compose logs -f web
   
   # Scale web containers
   docker-compose up -d --scale web=3
   
   # Update application
   docker-compose pull web
   docker-compose up -d web
   
   # Backup database
   docker-compose exec postgres pg_dump -U pmhuser pmh_production > backup.sql
   
   # Restore database
   docker-compose exec -T postgres psql -U pmhuser pmh_production < backup.sql

Cloud Platform Deployments
--------------------------

AWS Deployment
~~~~~~~~~~~~~

**1. Infrastructure as Code (Terraform):**

.. code-block:: hcl

   # aws-infrastructure.tf
   provider "aws" {
     region = var.aws_region
   }
   
   # VPC Configuration
   resource "aws_vpc" "pmh_vpc" {
     cidr_block           = "10.0.0.0/16"
     enable_dns_hostnames = true
     enable_dns_support   = true
     
     tags = {
       Name = "pmh-vpc"
     }
   }
   
   # Subnets
   resource "aws_subnet" "public" {
     count             = 2
     vpc_id            = aws_vpc.pmh_vpc.id
     cidr_block        = "10.0.${count.index + 1}.0/24"
     availability_zone = data.aws_availability_zones.available.names[count.index]
     
     map_public_ip_on_launch = true
     
     tags = {
       Name = "pmh-public-subnet-${count.index + 1}"
     }
   }
   
   resource "aws_subnet" "private" {
     count             = 2
     vpc_id            = aws_vpc.pmh_vpc.id
     cidr_block        = "10.0.${count.index + 10}.0/24"
     availability_zone = data.aws_availability_zones.available.names[count.index]
     
     tags = {
       Name = "pmh-private-subnet-${count.index + 1}"
     }
   }
   
   # Application Load Balancer
   resource "aws_lb" "pmh_alb" {
     name               = "pmh-alb"
     internal           = false
     load_balancer_type = "application"
     security_groups    = [aws_security_group.alb.id]
     subnets            = aws_subnet.public[*].id
     
     enable_deletion_protection = true
     
     tags = {
       Name = "pmh-alb"
     }
   }
   
   # ECS Cluster
   resource "aws_ecs_cluster" "pmh_cluster" {
     name = "pmh-cluster"
     
     capacity_providers = ["FARGATE", "FARGATE_SPOT"]
     
     default_capacity_provider_strategy {
       capacity_provider = "FARGATE"
       weight           = 1
     }
   }
   
   # RDS Database
   resource "aws_db_instance" "pmh_db" {
     identifier = "pmh-database"
     
     engine         = "postgres"
     engine_version = "15.4"
     instance_class = "db.t3.micro"
     
     allocated_storage     = 20
     max_allocated_storage = 100
     storage_type          = "gp2"
     storage_encrypted     = true
     
     db_name  = "pmh_production"
     username = "pmhuser"
     password = var.db_password
     
     vpc_security_group_ids = [aws_security_group.rds.id]
     db_subnet_group_name   = aws_db_subnet_group.pmh_db.name
     
     backup_retention_period = 7
     backup_window          = "03:00-04:00"
     maintenance_window     = "sun:04:00-sun:05:00"
     
     skip_final_snapshot = false
     final_snapshot_identifier = "pmh-db-final-snapshot"
     
     tags = {
       Name = "pmh-database"
     }
   }
   
   # ElastiCache Redis
   resource "aws_elasticache_subnet_group" "pmh_cache" {
     name       = "pmh-cache-subnet"
     subnet_ids = aws_subnet.private[*].id
   }
   
   resource "aws_elasticache_replication_group" "pmh_redis" {
     replication_group_id       = "pmh-redis"
     description                = "Redis for Python Mastery Hub"
     
     node_type                  = "cache.t3.micro"
     port                       = 6379
     parameter_group_name       = "default.redis7"
     
     num_cache_clusters         = 2
     automatic_failover_enabled = true
     multi_az_enabled          = true
     
     subnet_group_name = aws_elasticache_subnet_group.pmh_cache.name
     security_group_ids = [aws_security_group.redis.id]
     
     at_rest_encryption_enabled = true
     transit_encryption_enabled = true
     auth_token                 = var.redis_auth_token
     
     tags = {
       Name = "pmh-redis"
     }
   }

**2. ECS Task Definition:**

.. code-block:: json

   {
     "family": "pmh-app",
     "networkMode": "awsvpc",
     "requiresCompatibilities": ["FARGATE"],
     "cpu": "512",
     "memory": "1024",
     "executionRoleArn": "arn:aws:iam::account:role/ecsTaskExecutionRole",
     "taskRoleArn": "arn:aws:iam::account:role/ecsTaskRole",
     "containerDefinitions": [
       {
         "name": "pmh-web",
         "image": "pythonmasteryhub/pmh:latest",
         "portMappings": [
           {
             "containerPort": 8000,
             "protocol": "tcp"
           }
         ],
         "environment": [
           {
             "name": "PMH_ENVIRONMENT",
             "value": "production"
           }
         ],
         "secrets": [
           {
             "name": "PMH_DATABASE_URL",
             "valueFrom": "arn:aws:secretsmanager:region:account:secret:pmh/database-url"
           },
           {
             "name": "PMH_SECRET_KEY",
             "valueFrom": "arn:aws:secretsmanager:region:account:secret:pmh/secret-key"
           }
         ],
         "logConfiguration": {
           "logDriver": "awslogs",
           "options": {
             "awslogs-group": "/ecs/pmh-app",
             "awslogs-region": "us-west-2",
             "awslogs-stream-prefix": "ecs"
           }
         },
         "healthCheck": {
           "command": ["CMD-SHELL", "curl -f http://localhost:8000/health || exit 1"],
           "interval": 30,
           "timeout": 5,
           "retries": 3
         }
       }
     ]
   }

Google Cloud Platform (GCP) Deployment
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

**1. Kubernetes Deployment:**

.. code-block:: yaml

   # gcp-k8s-deployment.yaml
   apiVersion: apps/v1
   kind: Deployment
   metadata:
     name: pmh-web
     namespace: production
   spec:
     replicas: 3
     selector:
       matchLabels:
         app: pmh-web
     template:
       metadata:
         labels:
           app: pmh-web
       spec:
         containers:
         - name: pmh-web
           image: gcr.io/your-project/pmh:latest
           ports:
           - containerPort: 8000
           env:
           - name: PMH_DATABASE_URL
             valueFrom:
               secretKeyRef:
                 name: pmh-secrets
                 key: database-url
           - name: PMH_SECRET_KEY
             valueFrom:
               secretKeyRef:
                 name: pmh-secrets
                 key: secret-key
           resources:
             requests:
               memory: "512Mi"
               cpu: "250m"
             limits:
               memory: "1Gi"
               cpu: "500m"
           livenessProbe:
             httpGet:
               path: /health
               port: 8000
             initialDelaySeconds: 30
             periodSeconds: 10
           readinessProbe:
             httpGet:
               path: /health/ready
               port: 8000
             initialDelaySeconds: 5
             periodSeconds: 5
   ---
   apiVersion: v1
   kind: Service
   metadata:
     name: pmh-web-service
     namespace: production
   spec:
     selector:
       app: pmh-web
     ports:
     - port: 80
       targetPort: 8000
     type: ClusterIP
   ---
   apiVersion: networking.gke.io/v1
   kind: ManagedCertificate
   metadata:
     name: pmh-ssl-cert
     namespace: production
   spec:
     domains:
     - your-domain.com
     - www.your-domain.com
   ---
   apiVersion: networking.k8s.io/v1
   kind: Ingress
   metadata:
     name: pmh-ingress
     namespace: production
     annotations:
       kubernetes.io/ingress.global-static-ip-name: pmh-ip
       networking.gke.io/managed-certificates: pmh-ssl-cert
       kubernetes.io/ingress.class: "gce"
   spec:
     rules:
     - host: your-domain.com
       http:
         paths:
         - path: /*
           pathType: ImplementationSpecific
           backend:
             service:
               name: pmh-web-service
               port:
                 number: 80

**2. Cloud SQL and Memorystore Setup:**

.. code-block:: bash

   # Create Cloud SQL instance
   gcloud sql instances create pmh-db \
     --database-version=POSTGRES_15 \
     --tier=db-f1-micro \
     --region=us-central1 \
     --backup-start-time=03:00 \
     --enable-bin-log \
     --storage-auto-increase
   
   # Create database
   gcloud sql databases create pmh_production --instance=pmh-db
   
   # Create user
   gcloud sql users create pmhuser --instance=pmh-db --password=secure_password
   
   # Create Redis instance
   gcloud redis instances create pmh-redis \
     --size=1 \
     --region=us-central1 \
     --redis-version=redis_6_x

Azure Deployment
~~~~~~~~~~~~~~~

**1. ARM Template:**

.. code-block:: json

   {
     "$schema": "https://schema.management.azure.com/schemas/2019-04-01/deploymentTemplate.json#",
     "contentVersion": "1.0.0.0",
     "parameters": {
       "webAppName": {
         "type": "string",
         "defaultValue": "pmh-webapp",
         "metadata": {
           "description": "Web app name."
         }
       },
       "location": {
         "type": "string",
         "defaultValue": "[resourceGroup().location]",
         "metadata": {
           "description": "Location for all resources."
         }
       }
     },
     "resources": [
       {
         "type": "Microsoft.Web/serverfarms",
         "apiVersion": "2021-02-01",
         "name": "[concat(parameters('webAppName'), '-plan')]",
         "location": "[parameters('location')]",
         "sku": {
           "name": "P1v2",
           "tier": "PremiumV2"
         },
         "kind": "linux",
         "properties": {
           "reserved": true
         }
       },
       {
         "type": "Microsoft.Web/sites",
         "apiVersion": "2021-02-01",
         "name": "[parameters('webAppName')]",
         "location": "[parameters('location')]",
         "dependsOn": [
           "[resourceId('Microsoft.Web/serverfarms', concat(parameters('webAppName'), '-plan'))]"
         ],
         "properties": {
           "serverFarmId": "[resourceId('Microsoft.Web/serverfarms', concat(parameters('webAppName'), '-plan'))]",
           "siteConfig": {
             "linuxFxVersion": "DOCKER|pythonmasteryhub/pmh:latest",
             "appSettings": [
               {
                 "name": "WEBSITES_ENABLE_APP_SERVICE_STORAGE",
                 "value": "false"
               },
               {
                 "name": "PMH_ENVIRONMENT",
                 "value": "production"
               }
             ]
           }
         }
       },
       {
         "type": "Microsoft.DBforPostgreSQL/flexibleServers",
         "apiVersion": "2021-06-01",
         "name": "[concat(parameters('webAppName'), '-db')]",
         "location": "[parameters('location')]",
         "properties": {
           "version": "13",
           "administratorLogin": "pmhuser",
           "administratorLoginPassword": "[parameters('dbPassword')]",
           "storage": {
             "storageSizeGB": 32
           },
           "backup": {
             "backupRetentionDays": 7,
             "geoRedundantBackup": "Disabled"
           }
         }
       }
     ]
   }

Security Configuration
---------------------

SSL/TLS Setup
~~~~~~~~~~~~

**1. SSL Certificate Management:**

.. code-block:: bash

   # Automated SSL with Certbot
   #!/bin/bash
   # ssl-renew.sh
   
   DOMAIN="your-domain.com"
   EMAIL="admin@your-domain.com"
   
   # Install certbot if not present
   if ! command -v certbot &> /dev/null; then
       sudo apt install -y certbot python3-certbot-nginx
   fi
   
   # Obtain certificate
   sudo certbot --nginx \
       --non-interactive \
       --agree-tos \
       --email $EMAIL \
       -d $DOMAIN \
       -d www.$DOMAIN
   
   # Setup automatic renewal
   (crontab -l 2>/dev/null; echo "0 12 * * * /usr/bin/certbot renew --quiet") | crontab -

**2. Security Headers Configuration:**

.. code-block:: nginx

   # Enhanced security headers
   add_header Strict-Transport-Security "max-age=63072000; includeSubDomains; preload" always;
   add_header X-Frame-Options "SAMEORIGIN" always;
   add_header X-Content-Type-Options "nosniff" always;
   add_header X-XSS-Protection "1; mode=block" always;
   add_header Referrer-Policy "strict-origin-when-cross-origin" always;
   add_header Content-Security-Policy "default-src 'self'; script-src 'self' 'unsafe-inline' https://cdn.jsdelivr.net; style-src 'self' 'unsafe-inline' https://fonts.googleapis.com; font-src 'self' https://fonts.gstatic.com; img-src 'self' data: https:; connect-src 'self';" always;
   add_header Permissions-Policy "camera=(), microphone=(), geolocation=(), payment=(), usb=(), magnetometer=(), accelerometer=(), gyroscope=()" always;

Firewall Configuration
~~~~~~~~~~~~~~~~~~~~~

**1. UFW (Ubuntu Firewall):**

.. code-block:: bash

   # Basic firewall setup
   sudo ufw default deny incoming
   sudo ufw default allow outgoing
   
   # Allow SSH (change port if using non-standard)
   sudo ufw allow 22/tcp
   
   # Allow HTTP and HTTPS
   sudo ufw allow 80/tcp
   sudo ufw allow 443/tcp
   
   # Allow database access only from application servers
   sudo ufw allow from 10.0.0.0/24 to any port 5432
   
   # Enable firewall
   sudo ufw --force enable
   
   # Check status
   sudo ufw status verbose

**2. Fail2Ban Configuration:**

.. code-block:: ini

   # /etc/fail2ban/jail.local
   [DEFAULT]
   bantime = 3600
   findtime = 600
   maxretry = 3
   
   [sshd]
   enabled = true
   port = ssh
   filter = sshd
   logpath = /var/log/auth.log
   maxretry = 3
   
   [nginx-http-auth]
   enabled = true
   filter = nginx-http-auth
   port = http,https
   logpath = /var/log/nginx/error.log
   
   [nginx-limit-req]
   enabled = true
   filter = nginx-limit-req
   port = http,https
   logpath = /var/log/nginx/error.log
   maxretry = 10

Database Security
~~~~~~~~~~~~~~~~

**1. PostgreSQL Security Hardening:**

.. code-block:: bash

   # /etc/postgresql/15/main/postgresql.conf
   
   # Connection settings
   listen_addresses = 'localhost'  # or specific IPs
   port = 5432
   max_connections = 100
   
   # Authentication
   password_encryption = scram-sha-256
   
   # Logging
   log_connections = on
   log_disconnections = on
   log_statement = 'all'
   log_min_duration_statement = 1000  # Log slow queries
   
   # Security
   ssl = on
   ssl_cert_file = '/etc/postgresql/15/main/server.crt'
   ssl_key_file = '/etc/postgresql/15/main/server.key'

**2. Database Access Control:**

.. code-block:: bash

   # /etc/postgresql/15/main/pg_hba.conf
   
   # Local connections
   local   all             postgres                                peer
   local   all             all                                     md5
   
   # IPv4 local connections
   host    all             all             127.0.0.1/32            scram-sha-256
   
   # Application server connections
   host    pmh_production  pmhuser         10.0.0.0/24             scram-sha-256
   
   # Deny all other connections
   host    all             all             0.0.0.0/0               reject

Monitoring and Alerting
-----------------------

Comprehensive Monitoring Setup
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

**1. Prometheus Configuration:**

.. code-block:: yaml

   # prometheus.yml
   global:
     scrape_interval: 15s
     evaluation_interval: 15s
   
   rule_files:
     - "alert_rules.yml"
   
   alerting:
     alertmanagers:
       - static_configs:
           - targets:
             - alertmanager:9093
   
   scrape_configs:
     - job_name: 'pmh-web'
       static_configs:
         - targets: ['localhost:8000']
       metrics_path: '/metrics'
       scrape_interval: 30s
   
     - job_name: 'postgres'
       static_configs:
         - targets: ['localhost:9187']
   
     - job_name: 'redis'
       static_configs:
         - targets: ['localhost:9121']
   
     - job_name: 'nginx'
       static_configs:
         - targets: ['localhost:9113']
   
     - job_name: 'node'
       static_configs:
         - targets: ['localhost:9100']

**2. Alert Rules:**

.. code-block:: yaml

   # alert_rules.yml
   groups:
   - name: pmh_alerts
     rules:
     - alert: HighErrorRate
       expr: rate(pmh_requests_total{status=~"5.."}[5m]) > 0.1
       for: 5m
       labels:
         severity: critical
       annotations:
         summary: "High error rate detected"
         description: "Error rate is {{ $value }} errors per second"
   
     - alert: DatabaseDown
       expr: up{job="postgres"} == 0
       for: 1m
       labels:
         severity: critical
       annotations:
         summary: "Database is down"
         description: "PostgreSQL database is not responding"
   
     - alert: HighMemoryUsage
       expr: (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes > 0.9
       for: 5m
       labels:
         severity: warning
       annotations:
         summary: "High memory usage"
         description: "Memory usage is above 90%"
   
     - alert: DiskSpaceLow
       expr: (node_filesystem_size_bytes - node_filesystem_free_bytes) / node_filesystem_size_bytes > 0.8
       for: 5m
       labels:
         severity: warning
       annotations:
         summary: "Low disk space"
         description: "Disk usage is above 80% on {{ $labels.device }}"

**3. Grafana Dashboard:**

.. code-block:: json

   {
     "dashboard": {
       "title": "Python Mastery Hub Monitoring",
       "panels": [
         {
           "title": "Request Rate",
           "type": "graph",
           "targets": [
             {
               "expr": "rate(pmh_requests_total[5m])",
               "legendFormat": "{{ method }} {{ endpoint }}"
             }
           ]
         },
         {
           "title": "Response Time",
           "type": "graph",
           "targets": [
             {
               "expr": "histogram_quantile(0.95, rate(pmh_request_duration_seconds_bucket[5m]))",
               "legendFormat": "95th percentile"
             }
           ]
         },
         {
           "title": "Active Users",
           "type": "singlestat",
           "targets": [
             {
               "expr": "pmh_active_users",
               "legendFormat": "Active Users"
             }
           ]
         }
       ]
     }
   }

Application Logging
~~~~~~~~~~~~~~~~~~

**1. Structured Logging Configuration:**

.. code-block:: python

   # logging_config.py
   LOGGING_CONFIG = {
       'version': 1,
       'disable_existing_loggers': False,
       'formatters': {
           'standard': {
               'format': '%(asctime)s [%(levelname)s] %(name)s: %(message)s'
           },
           'json': {
               'format': '%(asctime)s %(levelname)s %(name)s %(message)s',
               'class': 'pythonjsonlogger.jsonlogger.JsonFormatter'
           }
       },
       'handlers': {
           'console': {
               'level': 'INFO',
               'class': 'logging.StreamHandler',
               'formatter': 'standard'
           },
           'file': {
               'level': 'DEBUG',
               'class': 'logging.handlers.RotatingFileHandler',
               'filename': '/var/log/pmh/app.log',
               'maxBytes': 10485760,  # 10MB
               'backupCount': 10,
               'formatter': 'json'
           },
           'error_file': {
               'level': 'ERROR',
               'class': 'logging.handlers.RotatingFileHandler',
               'filename': '/var/log/pmh/error.log',
               'maxBytes': 10485760,
               'backupCount': 5,
               'formatter': 'json'
           }
       },
       'loggers': {
           'pmh': {
               'handlers': ['console', 'file', 'error_file'],
               'level': 'DEBUG',
               'propagate': False
           },
           'sqlalchemy.engine': {
               'handlers': ['file'],
               'level': 'INFO',
               'propagate': False
           }
       },
       'root': {
           'level': 'INFO',
           'handlers': ['console']
       }
   }

**2. Log Aggregation with ELK Stack:**

.. code-block:: yaml

   # docker-compose-elk.yml
   version: '3.8'
   services:
     elasticsearch:
       image: docker.elastic.co/elasticsearch/elasticsearch:8.8.0
       environment:
         - discovery.type=single-node
         - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
       volumes:
         - elasticsearch_data:/usr/share/elasticsearch/data
       ports:
         - "9200:9200"
   
     logstash:
       image: docker.elastic.co/logstash/logstash:8.8.0
       volumes:
         - ./logstash/pipeline:/usr/share/logstash/pipeline
         - /var/log/pmh:/var/log/pmh:ro
       depends_on:
         - elasticsearch
   
     kibana:
       image: docker.elastic.co/kibana/kibana:8.8.0
       ports:
         - "5601:5601"
       environment:
         - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
       depends_on:
         - elasticsearch

Backup and Disaster Recovery
----------------------------

Database Backup Strategy
~~~~~~~~~~~~~~~~~~~~~~~

**1. Automated Backup Script:**

.. code-block:: bash

   #!/bin/bash
   # backup-database.sh
   
   set -e
   
   # Configuration
   DB_NAME="pmh_production"
   DB_USER="pmhuser"
   BACKUP_DIR="/backup/database"
   RETENTION_DAYS=30
   
   # Create backup directory
   mkdir -p $BACKUP_DIR
   
   # Generate backup filename
   TIMESTAMP=$(date +%Y%m%d_%H%M%S)
   BACKUP_FILE="$BACKUP_DIR/pmh_backup_$TIMESTAMP.sql"
   
   # Create backup
   echo "Creating database backup..."
   pg_dump -h localhost -U $DB_USER -d $DB_NAME > $BACKUP_FILE
   
   # Compress backup
   gzip $BACKUP_FILE
   
   # Upload to cloud storage (AWS S3 example)
   aws s3 cp "$BACKUP_FILE.gz" "s3://pmh-backups/database/"
   
   # Clean up old local backups
   find $BACKUP_DIR -name "*.sql.gz" -mtime +$RETENTION_DAYS -delete
   
   echo "Backup completed: $BACKUP_FILE.gz"

**2. Point-in-Time Recovery Setup:**

.. code-block:: bash

   # Enable WAL archiving in postgresql.conf
   wal_level = replica
   archive_mode = on
   archive_command = 'aws s3 cp %p s3://pmh-backups/wal/%f'
   archive_timeout = 300  # 5 minutes
   
   # Configure recovery settings
   restore_command = 'aws s3 cp s3://pmh-backups/wal/%f %p'
   recovery_target_time = '2024-01-20 14:30:00'

File Backup and Sync
~~~~~~~~~~~~~~~~~~~

**1. User Upload Backup:**

.. code-block:: bash

   #!/bin/bash
   # backup-files.sh
   
   UPLOAD_DIR="/home/pmhuser/pmh/uploads"
   BACKUP_BUCKET="s3://pmh-backups/files"
   
   # Sync uploads to S3
   aws s3 sync $UPLOAD_DIR $BACKUP_BUCKET --delete
   
   # Create local backup archive
   tar -czf "/backup/files/uploads_$(date +%Y%m%d).tar.gz" -C $UPLOAD_DIR .

**2. Configuration Backup:**

.. code-block:: bash

   #!/bin/bash
   # backup-config.sh
   
   CONFIG_FILES=(
       "/home/pmhuser/pmh/production-config.yaml"
       "/etc/nginx/sites-available/pmh"
       "/etc/postgresql/15/main/postgresql.conf"
       "/etc/postgresql/15/main/pg_hba.conf"
       "/etc/systemd/system/pmh.service"
   )
   
   BACKUP_DIR="/backup/config"
   mkdir -p $BACKUP_DIR
   
   for file in "${CONFIG_FILES[@]}"; do
       if [ -f "$file" ]; then
           cp "$file" "$BACKUP_DIR/"
       fi
   done
   
   # Create archive
   tar -czf "/backup/config_$(date +%Y%m%d).tar.gz" -C $BACKUP_DIR .

Disaster Recovery Plan
~~~~~~~~~~~~~~~~~~~~~

**1. Recovery Procedures:**

.. code-block:: bash

   #!/bin/bash
   # disaster-recovery.sh
   
   echo "Starting disaster recovery process..."
   
   # 1. Restore database
   echo "Restoring database..."
   LATEST_BACKUP=$(aws s3 ls s3://pmh-backups/database/ | sort | tail -1 | awk '{print $4}')
   aws s3 cp "s3://pmh-backups/database/$LATEST_BACKUP" /tmp/
   gunzip "/tmp/$LATEST_BACKUP"
   psql -U pmhuser -d pmh_production < "/tmp/${LATEST_BACKUP%.gz}"
   
   # 2. Restore files
   echo "Restoring user files..."
   aws s3 sync s3://pmh-backups/files/ /home/pmhuser/pmh/uploads/
   
   # 3. Restore configuration
   echo "Restoring configuration..."
   aws s3 sync s3://pmh-backups/config/ /tmp/config/
   # Manual step: review and apply configurations
   
   # 4. Start services
   echo "Starting services..."
   sudo systemctl start postgresql
   sudo systemctl start redis-server
   sudo systemctl start pmh
   sudo systemctl start nginx
   
   echo "Disaster recovery completed. Please verify system functionality."

**2. Recovery Time Objectives (RTO) and Recovery Point Objectives (RPO):**

.. code-block:: text

   Disaster Recovery Targets:
   
   RTO (Recovery Time Objective):
   - Database: 1 hour
   - Application: 30 minutes
   - Full system: 2 hours
   
   RPO (Recovery Point Objective):
   - Database: 15 minutes (WAL archiving)
   - User files: 1 hour (hourly sync)
   - Configuration: 24 hours (daily backup)

Maintenance and Updates
----------------------

Update Management
~~~~~~~~~~~~~~~~

**1. Application Updates:**

.. code-block:: bash

   #!/bin/bash
   # update-pmh.sh
   
   set -e
   
   echo "Starting Python Mastery Hub update..."
   
   # Create backup before update
   ./backup-database.sh
   ./backup-files.sh
   
   # Switch to maintenance mode
   sudo systemctl stop pmh
   
   # Update application
   sudo su - pmhuser << 'EOF'
   cd /home/pmhuser/pmh
   source pmh-env/bin/activate
   pip install --upgrade python-mastery-hub
   
   # Run database migrations
   pmh db migrate
   
   # Collect static files
   pmh web collectstatic --noinput
   EOF
   
   # Start services
   sudo systemctl start pmh
   
   # Verify update
   sleep 30
   if curl -f http://localhost:8000/health; then
       echo "Update completed successfully"
   else
       echo "Update failed, rolling back..."
       # Rollback procedures here
   fi

**2. System Updates:**

.. code-block:: bash

   #!/bin/bash
   # system-maintenance.sh
   
   # Update package lists
   sudo apt update
   
   # Install security updates
   sudo apt upgrade -y
   
   # Clean up
   sudo apt autoremove -y
   sudo apt autoclean
   
   # Update SSL certificates
   sudo certbot renew --quiet
   
   # Restart services if needed
   if [ -f /var/run/reboot-required ]; then
       echo "Reboot required. Schedule maintenance window."
   fi

Performance Monitoring
~~~~~~~~~~~~~~~~~~~~~

**1. Performance Metrics Collection:**

.. code-block:: python

   # performance_monitor.py
   import psutil
   import time
   import json
   from datetime import datetime
   
   def collect_system_metrics():
       """Collect system performance metrics."""
       
       metrics = {
           'timestamp': datetime.now().isoformat(),
           'cpu': {
               'percent': psutil.cpu_percent(interval=1),
               'count': psutil.cpu_count(),
               'load_avg': psutil.getloadavg()
           },
           'memory': {
               'total': psutil.virtual_memory().total,
               'available': psutil.virtual_memory().available,
               'percent': psutil.virtual_memory().percent
           },
           'disk': {
               'total': psutil.disk_usage('/').total,
               'free': psutil.disk_usage('/').free,
               'percent': psutil.disk_usage('/').percent
           },
           'network': psutil.net_io_counters()._asdict()
       }
       
       return metrics
   
   def save_metrics(metrics):
       """Save metrics to file."""
       with open('/var/log/pmh/performance.log', 'a') as f:
           f.write(json.dumps(metrics) + '\n')
   
   if __name__ == "__main__":
       while True:
           metrics = collect_system_metrics()
           save_metrics(metrics)
           time.sleep(60)  # Collect every minute

**2. Database Performance Monitoring:**

.. code-block:: sql

   -- Create performance monitoring views
   CREATE OR REPLACE VIEW slow_queries AS
   SELECT 
       query,
       calls,
       total_time,
       mean_time,
       rows,
       100.0 * shared_blks_hit / nullif(shared_blks_hit + shared_blks_read, 0) AS hit_percent
   FROM pg_stat_statements 
   WHERE mean_time > 100  -- Queries taking more than 100ms on average
   ORDER BY mean_time DESC;
   
   -- Monitor connection usage
   CREATE OR REPLACE VIEW connection_stats AS
   SELECT 
       datname,
       state,
       COUNT(*) as connections
   FROM pg_stat_activity 
   GROUP BY datname, state;

Troubleshooting Common Issues
----------------------------

Application Issues
~~~~~~~~~~~~~~~~~

**1. High Memory Usage:**

.. code-block:: bash

   # Check memory usage
   free -h
   ps aux --sort=-%mem | head -10
   
   # Check Python Mastery Hub processes
   sudo systemctl status pmh
   journalctl -u pmh -f
   
   # Restart if necessary
   sudo systemctl restart pmh

**2. Database Connection Issues:**

.. code-block:: bash

   # Check PostgreSQL status
   sudo systemctl status postgresql
   
   # Check connections
   sudo -u postgres psql -c "SELECT * FROM pg_stat_activity;"
   
   # Check configuration
   sudo -u postgres psql -c "SHOW max_connections;"
   sudo -u postgres psql -c "SHOW shared_buffers;"

**3. SSL Certificate Issues:**

.. code-block:: bash

   # Check certificate expiration
   openssl x509 -in /etc/letsencrypt/live/your-domain.com/fullchain.pem -noout -dates
   
   # Test SSL configuration
   openssl s_client -connect your-domain.com:443 -servername your-domain.com
   
   # Renew certificates
   sudo certbot renew --dry-run
   sudo certbot renew

Network and Connectivity
~~~~~~~~~~~~~~~~~~~~~~~

**1. DNS Issues:**

.. code-block:: bash

   # Check DNS resolution
   nslookup your-domain.com
   dig your-domain.com
   
   # Check A records
   dig A your-domain.com
   dig AAAA your-domain.com

**2. Load Balancer Issues:**

.. code-block:: bash

   # Check Nginx status
   sudo systemctl status nginx
   
   # Test configuration
   sudo nginx -t
   
   # Check upstream servers
   curl -I http://localhost:8000/health

Scaling Considerations
---------------------

Horizontal Scaling
~~~~~~~~~~~~~~~~~

**1. Multi-Server Setup:**

.. code-block:: text

   Scaled Architecture:
   
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Load Balancer  â”‚    â”‚   Web Server 1   â”‚
   â”‚   (Nginx/HAProxyâ”‚â”€â”€â”€â”€â”‚   (PMH App)      â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚   Web Server 2   â”‚
            â”‚              â”‚   (PMH App)      â”‚
            â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚   Web Server 3   â”‚
                           â”‚   (PMH App)      â”‚
                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           â”‚    Database      â”‚
                           â”‚   (PostgreSQL)   â”‚
                           â”‚   with Replica   â”‚
                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

**2. Session Management for Scaling:**

.. code-block:: python

   # Redis session configuration
   SESSION_CONFIG = {
       'session_type': 'redis',
       'redis_host': 'redis-cluster',
       'redis_port': 6379,
       'redis_password': 'secure_password',
       'session_permanent': False,
       'session_use_signer': True,
       'session_key_prefix': 'pmh:session:',
       'session_redis_db': 1
   }

Database Scaling
~~~~~~~~~~~~~~~

**1. Read Replicas Setup:**

.. code-block:: bash

   # Primary server configuration
   # postgresql.conf
   wal_level = replica
   max_wal_senders = 3
   max_replication_slots = 3
   synchronous_commit = on
   
   # Create replication user
   sudo -u postgres psql
   CREATE USER replicator REPLICATION LOGIN ENCRYPTED PASSWORD 'repl_password';

**2. Connection Pooling:**

.. code-block:: bash

   # Install and configure PgBouncer
   sudo apt install pgbouncer
   
   # /etc/pgbouncer/pgbouncer.ini
   [databases]
   pmh_production = host=localhost port=5432 dbname=pmh_production
   
   [pgbouncer]
   listen_addr = 127.0.0.1
   listen_port = 6432
   auth_type = md5
   auth_file = /etc/pgbouncer/userlist.txt
   pool_mode = transaction
   max_client_conn = 1000
   default_pool_size = 25

Conclusion
----------

This comprehensive deployment guide covered:

âœ… **Single-server deployment** for small to medium installations
âœ… **Docker containerization** for consistent environments
âœ… **Cloud platform deployment** on AWS, GCP, and Azure
âœ… **Security configuration** with SSL, firewalls, and hardening
âœ… **Monitoring and alerting** with Prometheus and Grafana
âœ… **Backup and disaster recovery** strategies
âœ… **Maintenance and updates** procedures
âœ… **Scaling considerations** for growing deployments

Key Takeaways
~~~~~~~~~~~~

**Start Simple, Scale Gradually:**
- Begin with a single-server deployment
- Add complexity as your user base grows
- Monitor performance and scale proactively

**Security First:**
- Implement security measures from day one
- Regular updates and security audits
- Follow principle of least privilege

**Plan for Disasters:**
- Regular automated backups
- Test recovery procedures
- Document all processes

**Monitor Everything:**
- Application performance metrics
- System resource usage
- User experience indicators

Next Steps
~~~~~~~~~

1. **Choose your deployment method** based on your requirements
2. **Implement monitoring** from the beginning
3. **Set up automated backups** before going live
4. **Test your deployment** thoroughly in a staging environment
5. **Plan for scaling** as your user base grows

Getting Help
~~~~~~~~~~~

- **Documentation**: Refer to the :doc:`../api/index` for detailed API information
- **Community**: Join our deployment discussion channels
- **Support**: Enterprise deployment support available
- **Consulting**: Professional deployment services for complex requirements

.. admonition:: Production Ready! ğŸš€
   :class: tip

   You now have comprehensive knowledge for deploying Python Mastery Hub in 
   production environments. Whether you're running a small educational instance 
   or a large-scale platform, these guidelines will help ensure a secure, 
   scalable, and maintainable deployment.
   
   **Remember**: Always test deployment procedures in a staging environment 
   before applying to production!